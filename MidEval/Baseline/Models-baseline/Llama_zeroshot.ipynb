{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11083956,"sourceType":"datasetVersion","datasetId":6908278},{"sourceId":11093349,"sourceType":"datasetVersion","datasetId":6915277}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T05:52:47.094911Z","iopub.execute_input":"2025-03-20T05:52:47.095175Z","iopub.status.idle":"2025-03-20T05:52:47.117630Z","shell.execute_reply.started":"2025-03-20T05:52:47.095139Z","shell.execute_reply":"2025-03-20T05:52:47.116757Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/intentconan-test-csv/test.csv\n/kaggle/input/intentconan/flan_t5_counterspeech.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom tqdm import tqdm  # For progress tracking\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n\n\nfile_path = \"/kaggle/input/intentconan-test-csv/test.csv\"\ndf = pd.read_csv(file_path)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:06:23.377616Z","iopub.execute_input":"2025-03-20T09:06:23.377952Z","iopub.status.idle":"2025-03-20T09:06:35.527699Z","shell.execute_reply.started":"2025-03-20T09:06:23.377926Z","shell.execute_reply":"2025-03-20T09:06:35.526403Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   index                                         hatespeech       csType  \\\n0     20  Women are basically childlike, they remain thi...  Informative   \n1     22  Women are basically childlike, they remain thi...   Denouncing   \n2     23  Women are basically childlike, they remain thi...     Positive   \n3     48  Minorities vote to strip wealth and power from...  Informative   \n4     49  Minorities vote to strip wealth and power from...  Questioning   \n\n                                       counterspeech  Suggest  Relevance  \\\n0  The characteristics you are referring to are a...      3.0        4.0   \n1  Nobody apart from people who spread misinforma...      2.0        3.0   \n2  It is a question of survival and happiness to ...      2.0        2.0   \n3  This is incorrect. jews could never be able to...      3.0        4.0   \n4                            Where is your evidence?      1.0        1.0   \n\n   Aggressive  Complexity  Comments source  ... hatespeechTarget  \\\n0         2.0         3.0       NaN  Human  ...            women   \n1         3.0         2.0       NaN  Human  ...            women   \n2         2.0         2.0       NaN  Human  ...            women   \n3         3.0         3.0       NaN  Human  ...             jews   \n4         3.0         1.0       NaN  Human  ...             jews   \n\n  powerDynamics                               prompt_offensiveness  \\\n0        gender  Analyze the offensiveness of the statement: Wo...   \n1        gender  Analyze the offensiveness of the statement: Wo...   \n2        gender  Analyze the offensiveness of the statement: Wo...   \n3      religion  Analyze the offensiveness of the statement: Mi...   \n4      religion  Analyze the offensiveness of the statement: Mi...   \n\n                                 prompt_target_group  \\\n0  Identify the group of people that the speaker ...   \n1  Identify the group of people that the speaker ...   \n2  Identify the group of people that the speaker ...   \n3  Identify the group of people that the speaker ...   \n4  Identify the group of people that the speaker ...   \n\n                               prompt_speaker_intent  \\\n0  Analyze the speaker's intention behind writing...   \n1  Analyze the speaker's intention behind writing...   \n2  Analyze the speaker's intention behind writing...   \n3  Analyze the speaker's intention behind writing...   \n4  Analyze the speaker's intention behind writing...   \n\n                               prompt_power_dynamics  \\\n0  Explain the underlying power dynamics between ...   \n1  Explain the underlying power dynamics between ...   \n2  Explain the underlying power dynamics between ...   \n3  Explain the underlying power dynamics between ...   \n4  Explain the underlying power dynamics between ...   \n\n                                  prompt_implication  \\\n0  Explain the implied meaning underlying the off...   \n1  Explain the implied meaning underlying the off...   \n2  Explain the implied meaning underlying the off...   \n3  Explain the implied meaning underlying the off...   \n4  Explain the implied meaning underlying the off...   \n\n                           prompt_emotional_reaction  \\\n0  Describe how the target group might feel emoti...   \n1  Describe how the target group might feel emoti...   \n2  Describe how the target group might feel emoti...   \n3  Describe how the target group might feel emoti...   \n4  Describe how the target group might feel emoti...   \n\n                           prompt_cognitive_reaction  \\\n0  Describe how the target group might react cogn...   \n1  Describe how the target group might react cogn...   \n2  Describe how the target group might react cogn...   \n3  Describe how the target group might react cogn...   \n4  Describe how the target group might react cogn...   \n\n                                prompt_cs_generation  \n0  Analyze the different aspects such as offensiv...  \n1  Analyze the different aspects such as offensiv...  \n2  Analyze the different aspects such as offensiv...  \n3  Analyze the different aspects such as offensiv...  \n4  Analyze the different aspects such as offensiv...  \n\n[5 rows x 32 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>hatespeech</th>\n      <th>csType</th>\n      <th>counterspeech</th>\n      <th>Suggest</th>\n      <th>Relevance</th>\n      <th>Aggressive</th>\n      <th>Complexity</th>\n      <th>Comments</th>\n      <th>source</th>\n      <th>...</th>\n      <th>hatespeechTarget</th>\n      <th>powerDynamics</th>\n      <th>prompt_offensiveness</th>\n      <th>prompt_target_group</th>\n      <th>prompt_speaker_intent</th>\n      <th>prompt_power_dynamics</th>\n      <th>prompt_implication</th>\n      <th>prompt_emotional_reaction</th>\n      <th>prompt_cognitive_reaction</th>\n      <th>prompt_cs_generation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20</td>\n      <td>Women are basically childlike, they remain thi...</td>\n      <td>Informative</td>\n      <td>The characteristics you are referring to are a...</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>Human</td>\n      <td>...</td>\n      <td>women</td>\n      <td>gender</td>\n      <td>Analyze the offensiveness of the statement: Wo...</td>\n      <td>Identify the group of people that the speaker ...</td>\n      <td>Analyze the speaker's intention behind writing...</td>\n      <td>Explain the underlying power dynamics between ...</td>\n      <td>Explain the implied meaning underlying the off...</td>\n      <td>Describe how the target group might feel emoti...</td>\n      <td>Describe how the target group might react cogn...</td>\n      <td>Analyze the different aspects such as offensiv...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22</td>\n      <td>Women are basically childlike, they remain thi...</td>\n      <td>Denouncing</td>\n      <td>Nobody apart from people who spread misinforma...</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>Human</td>\n      <td>...</td>\n      <td>women</td>\n      <td>gender</td>\n      <td>Analyze the offensiveness of the statement: Wo...</td>\n      <td>Identify the group of people that the speaker ...</td>\n      <td>Analyze the speaker's intention behind writing...</td>\n      <td>Explain the underlying power dynamics between ...</td>\n      <td>Explain the implied meaning underlying the off...</td>\n      <td>Describe how the target group might feel emoti...</td>\n      <td>Describe how the target group might react cogn...</td>\n      <td>Analyze the different aspects such as offensiv...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23</td>\n      <td>Women are basically childlike, they remain thi...</td>\n      <td>Positive</td>\n      <td>It is a question of survival and happiness to ...</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>Human</td>\n      <td>...</td>\n      <td>women</td>\n      <td>gender</td>\n      <td>Analyze the offensiveness of the statement: Wo...</td>\n      <td>Identify the group of people that the speaker ...</td>\n      <td>Analyze the speaker's intention behind writing...</td>\n      <td>Explain the underlying power dynamics between ...</td>\n      <td>Explain the implied meaning underlying the off...</td>\n      <td>Describe how the target group might feel emoti...</td>\n      <td>Describe how the target group might react cogn...</td>\n      <td>Analyze the different aspects such as offensiv...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48</td>\n      <td>Minorities vote to strip wealth and power from...</td>\n      <td>Informative</td>\n      <td>This is incorrect. jews could never be able to...</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>Human</td>\n      <td>...</td>\n      <td>jews</td>\n      <td>religion</td>\n      <td>Analyze the offensiveness of the statement: Mi...</td>\n      <td>Identify the group of people that the speaker ...</td>\n      <td>Analyze the speaker's intention behind writing...</td>\n      <td>Explain the underlying power dynamics between ...</td>\n      <td>Explain the implied meaning underlying the off...</td>\n      <td>Describe how the target group might feel emoti...</td>\n      <td>Describe how the target group might react cogn...</td>\n      <td>Analyze the different aspects such as offensiv...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>49</td>\n      <td>Minorities vote to strip wealth and power from...</td>\n      <td>Questioning</td>\n      <td>Where is your evidence?</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>Human</td>\n      <td>...</td>\n      <td>jews</td>\n      <td>religion</td>\n      <td>Analyze the offensiveness of the statement: Mi...</td>\n      <td>Identify the group of people that the speaker ...</td>\n      <td>Analyze the speaker's intention behind writing...</td>\n      <td>Explain the underlying power dynamics between ...</td>\n      <td>Explain the implied meaning underlying the off...</td>\n      <td>Describe how the target group might feel emoti...</td>\n      <td>Describe how the target group might react cogn...</td>\n      <td>Analyze the different aspects such as offensiv...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint( \"Using device:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T05:53:07.239840Z","iopub.execute_input":"2025-03-20T05:53:07.240083Z","iopub.status.idle":"2025-03-20T05:53:07.293499Z","shell.execute_reply.started":"2025-03-20T05:53:07.240063Z","shell.execute_reply":"2025-03-20T05:53:07.292636Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nimport pandas as pd\nfrom tqdm import tqdm  # Progress bar\n\nmodel_name = \"google/flan-t5-large\"  \ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T18:33:31.981293Z","iopub.execute_input":"2025-03-19T18:33:31.981675Z","iopub.status.idle":"2025-03-19T18:33:58.056205Z","shell.execute_reply.started":"2025-03-19T18:33:31.981637Z","shell.execute_reply":"2025-03-19T18:33:58.055409Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a56d6726a4b24ba59537709be947c14c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6410bf460f3d4a329adb05ba88d8b979"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"183c715c1b1d45229f43019187d844e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5176894087844fa8c7c165bc2932d87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d011b97414c9418399e13adaf3838e48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36163610d76c41c5972335a381f0053f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc9ac26caf7d41fcad4d7c8077e4c43c"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"print(\"Model Device:\", next(model.parameters()).device)  # Should print \"cuda\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T18:33:58.057427Z","iopub.execute_input":"2025-03-19T18:33:58.058117Z","iopub.status.idle":"2025-03-19T18:33:58.062848Z","shell.execute_reply.started":"2025-03-19T18:33:58.058080Z","shell.execute_reply":"2025-03-19T18:33:58.062021Z"}},"outputs":[{"name":"stdout","text":"Model Device: cuda:0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def generate_counterspeech_flan_t5(hate_speech, intent):\n    \"\"\"Generates counterspeech using Flan-T5 on GPU.\"\"\"\n    prompt = f\"\"\"\n        You are an expert in counterspeech generation. Your task is to generate an effective {intent} counterspeech response to the following hate speech.\n\n        ### Hate Speech:\n        {hate_speech}\n\n        ### Expected Response:\n        Your response should be a strong {intent} counterspeech that directly addresses the hate speech.\n    \"\"\"\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)  # Move inputs to GPU\n    with torch.no_grad():  # Disable gradient tracking for faster inference\n        outputs = model.generate(\n            **inputs, \n            max_new_tokens=250,  # Prevent cutoff\n            repetition_penalty=1.2, \n            no_repeat_ngram_size=3,  \n            temperature=0.7,  \n            top_k=50,  \n            top_p=0.9\n        )\n\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n\ndf[\"FlanT5_counterspeech\"] = \"\"\n\nprint(\"\\n Generating counterspeech using Flan-T5 on GPU...\")\n\n\nfor i in tqdm(range(len(df)), desc=\"Processing Hate Speech with Flan-T5\"):\n    df.at[i, \"FlanT5_counterspeech\"] = generate_counterspeech_flan_t5(\n        df.at[i, \"hatespeech\"], df.at[i, \"csType\"]\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T18:33:58.063577Z","iopub.execute_input":"2025-03-19T18:33:58.063815Z","iopub.status.idle":"2025-03-19T19:01:45.415083Z","shell.execute_reply.started":"2025-03-19T18:33:58.063796Z","shell.execute_reply":"2025-03-19T19:01:45.414235Z"}},"outputs":[{"name":"stdout","text":"\n Generating counterspeech using Flan-T5 on GPU...\n","output_type":"stream"},{"name":"stderr","text":"Processing Hate Speech with Flan-T5:   0%|          | 0/2971 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\nProcessing Hate Speech with Flan-T5: 100%|██████████| 2971/2971 [27:37<00:00,  1.79it/s]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"df.to_csv(\"flan_t5_counterspeech.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T19:01:58.933881Z","iopub.execute_input":"2025-03-19T19:01:58.934169Z","iopub.status.idle":"2025-03-19T19:01:59.091893Z","shell.execute_reply.started":"2025-03-19T19:01:58.934148Z","shell.execute_reply":"2025-03-19T19:01:59.090966Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"%pip install together ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:06:05.646434Z","iopub.execute_input":"2025-03-20T09:06:05.646795Z","iopub.status.idle":"2025-03-20T09:06:14.115897Z","shell.execute_reply.started":"2025-03-20T09:06:05.646770Z","shell.execute_reply":"2025-03-20T09:06:14.114469Z"}},"outputs":[{"name":"stdout","text":"Collecting together\n  Downloading together-1.4.6-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.10/dist-packages (from together) (3.11.12)\nRequirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from together) (8.1.7)\nRequirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from together) (0.2.0)\nRequirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.10/dist-packages (from together) (3.17.0)\nRequirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from together) (1.26.4)\nCollecting pillow<12.0.0,>=11.1.0 (from together)\n  Downloading pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\nRequirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.10/dist-packages (from together) (19.0.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.10/dist-packages (from together) (2.11.0a2)\nRequirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from together) (2.32.3)\nRequirement already satisfied: rich<14.0.0,>=13.8.1 in /usr/local/lib/python3.10/dist-packages (from together) (13.9.4)\nRequirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from together) (0.9.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.10/dist-packages (from together) (4.67.1)\nRequirement already satisfied: typer<0.16,>=0.9 in /usr/local/lib/python3.10/dist-packages (from together) (0.15.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.23.5->together) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.23.5->together) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.23.5->together) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.23.5->together) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.23.5->together) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.23.5->together) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.29.0)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (2025.1.31)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.8.1->together) (2.19.1)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.16,>=0.9->together) (1.5.4)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.23.5->together) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.23.5->together) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.5->together) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.23.5->together) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.23.5->together) (2024.2.0)\nDownloading together-1.4.6-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pillow, together\n  Attempting uninstall: pillow\n    Found existing installation: pillow 11.0.0\n    Uninstalling pillow-11.0.0:\n      Successfully uninstalled pillow-11.0.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nmlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\nplotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pillow-11.1.0 together-1.4.6\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from together import Together\n\n\nclient = Together(api_key=\"1e89efbd5c30c3251be93683f4130b5c35b0146befe5f68bd006ae30f28430cf\")  \n\n\ndef generate_counterspeech_togetherai(hate_speech, intent):\n    \"\"\"Generates counterspeech using LLaMA 3.3 70B via TogetherAI API\"\"\"\n    \n    \n    prompt = f\"\"\"### Counterspeech Generation Task\n\nYou are an expert in counterspeech. Generate a **{intent}** counterspeech response to the following hate speech:\n\n**Hate Speech Instance:**\n{hate_speech}\n\n---\n\n### Expected Response\nYour response should be a **{intent}** style counterspeech that directly addresses the hate speech instance.\n\"\"\"\n\n    try:\n        \n        response = client.chat.completions.create(\n            model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",  \n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            max_tokens=250,  \n            temperature=0.7,\n            top_p=0.9,\n            top_k=50,\n            repetition_penalty=1,\n            stop=[\"\\n\\n\",\"<|eot_id|>\", \"<|eom_id|>\"],\n            stream=False  \n        )\n\n        \n        return response.choices[0].message.content if response.choices else \"No response generated.\"\n    \n    except Exception as e:\n        print(\"Error with TogetherAI API:\", e)\n        return \"\"\n\ndf[\"Llama3_counterspeech\"] = \"\"\n\nprint(\"\\nGenerating counterspeech using TogetherAI LLaMA 3.3 70B...\")\n\n\nfor i in tqdm(range(len(df)), desc=\"Processing Hate Speech\"):\n    df.at[i, \"Llama3_counterspeech\"] = generate_counterspeech_togetherai(\n        df.at[i, \"hatespeech\"], df.at[i, \"csType\"]\n    )\n\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:10:51.211013Z","iopub.execute_input":"2025-03-20T09:10:51.211403Z","iopub.status.idle":"2025-03-20T16:03:10.083648Z","shell.execute_reply.started":"2025-03-20T09:10:51.211373Z","shell.execute_reply":"2025-03-20T16:03:10.081302Z"}},"outputs":[{"name":"stdout","text":"\nGenerating counterspeech using TogetherAI LLaMA 3.3 70B...\n","output_type":"stream"},{"name":"stderr","text":"Processing Hate Speech: 100%|██████████| 2971/2971 [6:52:18<00:00,  8.33s/it]    \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"df.to_csv(\"Llamazeroshot_counterspeech.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T16:03:10.513521Z","iopub.execute_input":"2025-03-20T16:03:10.513918Z","iopub.status.idle":"2025-03-20T16:03:10.711232Z","shell.execute_reply.started":"2025-03-20T16:03:10.513878Z","shell.execute_reply":"2025-03-20T16:03:10.709996Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"newdf = df[[\"Llama3_counterspeech\"]]\nnewdf.to_csv(\"Llama_cs.csv\", index = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:09:29.537721Z","iopub.execute_input":"2025-03-20T09:09:29.538066Z","iopub.status.idle":"2025-03-20T09:09:29.555956Z","shell.execute_reply.started":"2025-03-20T09:09:29.538040Z","shell.execute_reply":"2025-03-20T09:09:29.554590Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom tqdm import tqdm\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\nmodel_name = \"google/flan-t5-large\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T16:33:33.339294Z","iopub.execute_input":"2025-03-20T16:33:33.339731Z","iopub.status.idle":"2025-03-20T16:34:08.220346Z","shell.execute_reply.started":"2025-03-20T16:33:33.339703Z","shell.execute_reply":"2025-03-20T16:34:08.219408Z"}},"outputs":[{"name":"stdout","text":"Using device: cpu\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4ee9699e0374d0bbf5262b5fdab137c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"833ebb7b9efb4d059f525f69062f611f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"025ae788a85741a3bf8b246e26d8b443"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9c86395db4f4b5281c10a996aa2c019"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dafd48f679034d95999c971961e7e57c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15e2c879c22d4ce6b57617012c4439ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9310ed4f1b31426cb82aede7f2e6c333"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"FEW_SHOT_EXAMPLES = [\n    {\n        \"hate_speech\": \"Maybe the UN could talk to those asian and african nations responsible for 90+ of the pollution in the oceans instead of insisting on this bullshit about climate change.\",\n        \"intent\": \"Positive\",\n        \"counterspeech\": \"You're right, ocean pollution is one of the main environmental problems we face, however, climate change is a global problem, and everyone should help to combat it, no matter where in the world you are from!\"\n    },\n    {\n        \"hate_speech\": \"Maybe the UN could talk to those asian and african nations responsible for 90+ of the pollution in the oceans instead of insisting on this bullshit about climate change.\",\n        \"intent\": \"Denouncing\",\n        \"counterspeech\": \"The world would be a better place if people were more tolerant to each other.\"\n    },\n    {\n        \"hate_speech\": \"Maybe the UN could talk to those asian and african nations responsible for 90+ of the pollution in the oceans instead of insisting on this bullshit about climate change.\",\n        \"intent\": \"Questioning\",\n        \"counterspeech\": \"Doesn't everyone on the planet have a responsibility towards the climate?\"\n    },\n    {\n        \"hate_speech\": \"Maybe the UN could talk to those asian and african nations responsible for 90+ of the pollution in the oceans instead of insisting on this bullshit about climate change.\",\n        \"intent\": \"Informative\",\n        \"counterspeech\": \"The us is the second most polluting country in the world - as the worldâ€™s biggest industrial and commercial power. we are all to blame here and need to work hand in hand to create sustainable change, as opposed to pointing the finger to others.\"\n    },\n    {\n        \"hate_speech\": \"Jews cannot be patriots, since their allegiance will always be to the state of Israel.\",\n        \"intent\": \"Informative\",\n        \"counterspeech\": \"You can have parents and grandparents born elsewhere, and still be a patriot for the country you were born in.\"\n    },\n    {\n        \"hate_speech\": \"Jews cannot be patriots, since their allegiance will always be to the state of Israel.\",\n        \"intent\": \"Questioning\",\n        \"counterspeech\": \"If you personally had some distant spanish or jewish heritage and you identified more as american surely that doesn't mean that you can't be an american patriot?\"\n    },\n    {\n        \"hate_speech\": \"Jews cannot be patriots, since their allegiance will always be to the state of Israel.\",\n        \"intent\": \"Denouncing\",\n        \"counterspeech\": \"My best friend is jewish, she volunteers to help woman, disadvantages children, and her whole family work to make the uk a better place.\"\n    },\n    {\n        \"hate_speech\": \"Jews cannot be patriots, since their allegiance will always be to the state of Israel.\",\n        \"intent\": \"Positive\",\n        \"counterspeech\": \"It is possible to love one's country and one's religious home. the two are not exclusive.\"\n    },\n    {\n        \"hate_speech\": \"The British people should use those houses, not immigrants.\",\n        \"intent\": \"Positive\",\n        \"counterspeech\": \"This country is big enough for all of us. we should look forward to welcoming people into our countries if they want to. integration is not hard. give these people a break.\"\n    },\n    {\n        \"hate_speech\": \"The British people should use those houses, not immigrants.\",\n        \"intent\": \"Questioning\",\n        \"counterspeech\": \"Who are you to command what houses should be occupied by whom? who gave you this authority?\"\n    },\n    {\n        \"hate_speech\": \"The British people should use those houses, not immigrants.\",\n        \"intent\": \"Informative\",\n        \"counterspeech\": \"There are enough empty homes in the uk for both migrants and veterans. migrants deserve to be treated humanely, try having some empathy. imagine if you were forced by circumstance to emigrate and have to live in poor conditions.\"\n    },\n    {\n        \"hate_speech\": \"The British people should use those houses, not immigrants.\",\n        \"intent\": \"Denouncing\",\n        \"counterspeech\": \"It is because of people like you that migrants do not feel safe in a place that they should call home. shame on you.\"\n    }\n    \n    \n]\n\ndef generate_counterspeech_flan_t5(hate_speech, intent):\n\n    few_shot_examples = \"\"\n    for example in FEW_SHOT_EXAMPLES:\n        few_shot_examples += f\"\"\"\nHate Speech: {example['hate_speech']}\nIntent: {example['intent']}\nExpected Counterspeech ({example['intent']} intent): {example['counterspeech']}\n\n---\n\"\"\"\n\n    prompt = f\"\"\"### Few-Shot Counterspeech Generation Task\n\nBelow are some examples of hate speech and their corresponding counterspeech responses based on different intents.\n\n{few_shot_examples}\n\nNow generate a counterspeech response for the following:\n\nHate Speech: {hate_speech}\nIntent: {intent}\nExpected Counterspeech ({intent} intent):\"\"\"\n\n    # Tokenize and generate response\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)  \n    with torch.no_grad():  \n        outputs = model.generate(\n            **inputs, \n            max_new_tokens=250,  \n            repetition_penalty=1.2, \n            no_repeat_ngram_size=3,  \n            temperature=0.5,   # Lower temperature for better intent control\n            top_k=50,  \n            top_p=0.9\n        )\n\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n\ndf[\"FlanT5_few_shot_counterspeech\"] = \"\"\n\nprint(\"\\n Generating counterspeech using Flan-T5 (Few-Shot) on GPU...\")\n\nfor i in tqdm(range(len(df)), desc=\"Processing Hate Speech with Flan-T5 Few-Shot\"):\n    df.at[i, \"FlanT5_few_shot_counterspeech\"] = generate_counterspeech_flan_t5_few_shot(\n        df.at[i, \"hatespeech\"], df.at[i, \"csType\"]\n    )\n\n\ndf.to_csv(\"flan_t5_few_shot_counterspeech.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T06:25:14.020571Z","iopub.execute_input":"2025-03-20T06:25:14.020968Z","iopub.status.idle":"2025-03-20T07:11:46.011806Z","shell.execute_reply.started":"2025-03-20T06:25:14.020943Z","shell.execute_reply":"2025-03-20T07:11:46.010771Z"}},"outputs":[{"name":"stdout","text":"\n Generating counterspeech using Flan-T5 (Few-Shot) on GPU...\n","output_type":"stream"},{"name":"stderr","text":"Processing Hate Speech with Flan-T5 Few-Shot: 100%|██████████| 2971/2971 [46:31<00:00,  1.06it/s]\n","output_type":"stream"}],"execution_count":16}]}