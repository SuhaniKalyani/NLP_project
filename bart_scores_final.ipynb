{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-22T12:10:57.142235Z",
     "iopub.status.busy": "2025-03-22T12:10:57.141680Z",
     "iopub.status.idle": "2025-03-22T12:11:20.262036Z",
     "shell.execute_reply": "2025-03-22T12:11:20.261169Z",
     "shell.execute_reply.started": "2025-03-22T12:10:57.142209Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer, Trainer, TrainingArguments, DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T07:34:25.758467Z",
     "iopub.status.busy": "2025-03-21T07:34:25.757832Z",
     "iopub.status.idle": "2025-03-21T07:34:43.678510Z",
     "shell.execute_reply": "2025-03-21T07:34:43.677457Z",
     "shell.execute_reply.started": "2025-03-21T07:34:25.758436Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34369f53870f4be28978e8ca0e6d39ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9c95676d3c46fe981509063df1d752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae42f8317054835849e2aa62b167297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f92cf89a38149229de31581a6a34075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044ab1baf81347c3bf331aaaa2e7933e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ed6928a71342ff94ff862e1904a770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Sample:\n",
      "                                           hatespeech       csType  \\\n",
      "0  Maybe the UN could talk to those asian and afr...  Informative   \n",
      "1  Maybe the UN could talk to those asian and afr...  Questioning   \n",
      "2  Maybe the UN could talk to those asian and afr...   Denouncing   \n",
      "3  Maybe the UN could talk to those asian and afr...     Positive   \n",
      "4  Juice Jews are worse that nukes. Caption to a ...  Informative   \n",
      "\n",
      "                                       counterspeech Suggest  Relevance  \\\n",
      "0  The us is the second most polluting country in...       3        4.0   \n",
      "1  Doesn't everyone on the planet have a responsi...                3.0   \n",
      "2  The world would be a better place if people we...       1        1.0   \n",
      "3  You're right, ocean pollution is one of the ma...       3        4.0   \n",
      "4  Anti-semitism is a serious problem that we nee...       2        3.0   \n",
      "\n",
      "   Aggressive  Complexity  Comments source  \\\n",
      "0         2.0         3.0       NaN  Human   \n",
      "1         2.0         2.0       NaN  Human   \n",
      "2         2.0         2.0       NaN  Human   \n",
      "3         2.0         2.0       NaN  Human   \n",
      "4         2.0         2.0       NaN  Human   \n",
      "\n",
      "                                               claim  ... hatespeechTarget  \\\n",
      "0  The UN should focus on Asian and African natio...  ...     asian_people   \n",
      "1  The UN should focus on Asian and African natio...  ...     asian_people   \n",
      "2  The UN should focus on Asian and African natio...  ...     asian_people   \n",
      "3  The UN should focus on Asian and African natio...  ...     asian_people   \n",
      "4                         Jews are worse than nukes.  ...             jews   \n",
      "\n",
      "  powerDynamics                               prompt_offensiveness  \\\n",
      "0        racial  Analyze the offensiveness of the statement: Ma...   \n",
      "1        racial  Analyze the offensiveness of the statement: Ma...   \n",
      "2        racial  Analyze the offensiveness of the statement: Ma...   \n",
      "3        racial  Analyze the offensiveness of the statement: Ma...   \n",
      "4      religion  Analyze the offensiveness of the statement: Ju...   \n",
      "\n",
      "                                 prompt_target_group  \\\n",
      "0  Identify the group of people that the speaker ...   \n",
      "1  Identify the group of people that the speaker ...   \n",
      "2  Identify the group of people that the speaker ...   \n",
      "3  Identify the group of people that the speaker ...   \n",
      "4  Identify the group of people that the speaker ...   \n",
      "\n",
      "                               prompt_speaker_intent  \\\n",
      "0  Analyze the speaker's intention behind writing...   \n",
      "1  Analyze the speaker's intention behind writing...   \n",
      "2  Analyze the speaker's intention behind writing...   \n",
      "3  Analyze the speaker's intention behind writing...   \n",
      "4  Analyze the speaker's intention behind writing...   \n",
      "\n",
      "                               prompt_power_dynamics  \\\n",
      "0  Explain the underlying power dynamics between ...   \n",
      "1  Explain the underlying power dynamics between ...   \n",
      "2  Explain the underlying power dynamics between ...   \n",
      "3  Explain the underlying power dynamics between ...   \n",
      "4  Explain the underlying power dynamics between ...   \n",
      "\n",
      "                                  prompt_implication  \\\n",
      "0  Explain the implied meaning underlying the off...   \n",
      "1  Explain the implied meaning underlying the off...   \n",
      "2  Explain the implied meaning underlying the off...   \n",
      "3  Explain the implied meaning underlying the off...   \n",
      "4  Explain the implied meaning underlying the off...   \n",
      "\n",
      "                           prompt_emotional_reaction  \\\n",
      "0  Describe how the target group might feel emoti...   \n",
      "1  Describe how the target group might feel emoti...   \n",
      "2  Describe how the target group might feel emoti...   \n",
      "3  Describe how the target group might feel emoti...   \n",
      "4  Describe how the target group might feel emoti...   \n",
      "\n",
      "                           prompt_cognitive_reaction  \\\n",
      "0  Describe how the target group might react cogn...   \n",
      "1  Describe how the target group might react cogn...   \n",
      "2  Describe how the target group might react cogn...   \n",
      "3  Describe how the target group might react cogn...   \n",
      "4  Describe how the target group might react cogn...   \n",
      "\n",
      "                                prompt_cs_generation  \n",
      "0  Analyze the different aspects such as offensiv...  \n",
      "1  Analyze the different aspects such as offensiv...  \n",
      "2  Analyze the different aspects such as offensiv...  \n",
      "3  Analyze the different aspects such as offensiv...  \n",
      "4  Analyze the different aspects such as offensiv...  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# loading BART model & tokenizer \n",
    "MODEL_NAME = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\").to(device)\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"/kaggle/input/intentconan2/train.csv\")\n",
    "val_df = pd.read_csv(\"/kaggle/input/intentconan2/validation.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/intentconan2/test.csv\")\n",
    "\n",
    "print(\"Train Dataset Sample:\\n\", train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T07:35:07.968982Z",
     "iopub.status.busy": "2025-03-21T07:35:07.968675Z",
     "iopub.status.idle": "2025-03-21T07:35:37.887897Z",
     "shell.execute_reply": "2025-03-21T07:35:37.887153Z",
     "shell.execute_reply.started": "2025-03-21T07:35:07.968959Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7f3d7af850429bb72a44b508bf6b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9532 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d5ac910d0349c5afba41f737db06d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1470 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc46b1678c04254b9af4da0b73efeea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2971 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [f\"Hate Speech: {hs} Intent: {intent}\" for hs, intent in zip(examples[\"hatespeech\"], examples[\"csType\"])]\n",
    "    targets = examples[\"counterspeech\"]\n",
    "\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(targets, max_length=250, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    #replacing padding token ids with -100 for loss function\n",
    "    labels[\"input_ids\"] = [\n",
    "        [(token if token != tokenizer.pad_token_id else -100) for token in label] for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "tokenized_datasets = DatasetDict({\n",
    "    \"train\": train_dataset.map(preprocess_function, batched=True),\n",
    "    \"validation\": val_dataset.map(preprocess_function, batched=True),\n",
    "    \"test\": test_dataset.map(preprocess_function, batched=True),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T07:35:37.889104Z",
     "iopub.status.busy": "2025-03-21T07:35:37.888811Z",
     "iopub.status.idle": "2025-03-21T08:54:37.454634Z",
     "shell.execute_reply": "2025-03-21T08:54:37.453651Z",
     "shell.execute_reply.started": "2025-03-21T07:35:37.889079Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "<ipython-input-5-0241d28ef573>:22: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1788' max='1788' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1788/1788 1:18:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.774300</td>\n",
       "      <td>1.878842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.402800</td>\n",
       "      <td>1.839502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.121200</td>\n",
       "      <td>1.834578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bart_finetuned_samples\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=3, \n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100, \n",
    "    report_to=\"none\",\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    save_total_limit=1,  # Keep only last checkpoint\n",
    ")\n",
    "\n",
    "\n",
    "# Data Collator for Padding\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"./bart_finetuned_model_samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T09:09:59.912981Z",
     "iopub.status.busy": "2025-03-21T09:09:59.912661Z",
     "iopub.status.idle": "2025-03-21T10:00:46.252209Z",
     "shell.execute_reply": "2025-03-21T10:00:46.251212Z",
     "shell.execute_reply.started": "2025-03-21T09:09:59.912959Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/bart/configuration_bart.py:176: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
      "  warnings.warn(\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating counterspeech using BART for 10 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Hate Speech:   0%|          | 10/2971 [00:10<49:44,  1.01s/it] You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Processing Hate Speech: 100%|██████████| 2971/2971 [50:44<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Counterspeech Samples:\n",
      "                                             hatespeech       csType  \\\n",
      "0     Women are basically childlike, they remain thi...  Informative   \n",
      "1     Women are basically childlike, they remain thi...   Denouncing   \n",
      "2     Women are basically childlike, they remain thi...     Positive   \n",
      "3     Minorities vote to strip wealth and power from...  Informative   \n",
      "4     Minorities vote to strip wealth and power from...  Questioning   \n",
      "...                                                 ...          ...   \n",
      "2966  The Holocaust never happened. It was a coverup...  Informative   \n",
      "2967  We cannot coexist with millions of Muslims in ...     Positive   \n",
      "2968  Women are basically childlike, they remain thi...  Informative   \n",
      "2969  Women do not have equal rights, they are subhu...  Questioning   \n",
      "2970  Women have no place in our society, its a mens...  Questioning   \n",
      "\n",
      "                                     BART_counterspeech  \n",
      "0     I understand that you may have some strong opi...  \n",
      "1     This statement is offensive and perpetuates ha...  \n",
      "2     I understand that you may have some strong opi...  \n",
      "3     It is important to counter hate speech with ac...  \n",
      "4     Why do you think it is acceptable to discrimin...  \n",
      "...                                                 ...  \n",
      "2966  The holocaust is a well-documented historical ...  \n",
      "2967  I understand that you may have concerns about ...  \n",
      "2968  I understand that you may have some strong opi...  \n",
      "2969  Why do you believe that women are subhuman? ca...  \n",
      "2970  Why do you believe that women are incapable of...  \n",
      "\n",
      "[2971 rows x 3 columns]\n",
      "\n",
      "Counterspeech generation complete! Results saved to /kaggle/working/test_counterspeech.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer, pipeline\n",
    "\n",
    "MODEL_PATH = \"./bart_finetuned_model_samples\"\n",
    "tokenizer = BartTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = BartForConditionalGeneration.from_pretrained(MODEL_PATH).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# loading test dataset & Reset Index\n",
    "test_df = pd.read_csv(\"/kaggle/input/intentconan2/test.csv\")\n",
    "test_df[\"BART_counterspeech\"] = \"\"  # Add empty column for results\n",
    "\n",
    "bart_generator = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,  \n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "\n",
    "def generate_counterspeech_bart(hate_speech, intent):\n",
    "    \"\"\"Generates counterspeech using fine-tuned BART\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"Generate a {intent} counterspeech response for the following hate speech:\n",
    "\n",
    "    Hate Speech: {hate_speech}\n",
    "\n",
    "    Expected Response ({intent} intent):\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = bart_generator(\n",
    "            prompt, \n",
    "            max_length=100,  \n",
    "            num_return_sequences=1, \n",
    "            temperature=0.7, \n",
    "            top_p=0.9, \n",
    "            repetition_penalty=1.0, \n",
    "            do_sample=True\n",
    "        )\n",
    "        \n",
    "        return response[0]['generated_text'].strip() if response else \"No response generated.\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error generating response with BART:\", e)\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "print(\"\\nGenerating counterspeech using BART for...\")\n",
    "\n",
    "for i in tqdm(range(len(test_df)), desc=\"Processing Hate Speech\"):\n",
    "    test_df.at[i, \"BART_counterspeech\"] = generate_counterspeech_bart(\n",
    "        test_df.at[i, \"hatespeech\"], test_df.at[i, \"csType\"]\n",
    "    )\n",
    "\n",
    "print(\"\\nGenerated Counterspeech Samples:\")\n",
    "print(test_df[[\"hatespeech\", \"csType\", \"BART_counterspeech\"]])\n",
    "\n",
    "output_file = \"/kaggle/working/test_counterspeech.csv\"\n",
    "test_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nCounterspeech generation complete! Results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:12:16.914872Z",
     "iopub.status.busy": "2025-03-22T12:12:16.914521Z",
     "iopub.status.idle": "2025-03-22T12:12:21.367735Z",
     "shell.execute_reply": "2025-03-22T12:12:21.366784Z",
     "shell.execute_reply.started": "2025-03-22T12:12:16.914846Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert_score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.5.1+cu121)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.2.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.47.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.7.5)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2025.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.29.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bert_score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bert_score) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->bert_score) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->bert_score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->bert_score) (2024.2.0)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bert_score\n",
      "Successfully installed bert_score-0.3.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:11:20.263577Z",
     "iopub.status.busy": "2025-03-22T12:11:20.262983Z",
     "iopub.status.idle": "2025-03-22T12:11:20.735974Z",
     "shell.execute_reply": "2025-03-22T12:11:20.735277Z",
     "shell.execute_reply.started": "2025-03-22T12:11:20.263540Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def calculate_bleu(reference, candidate):\n",
    "    \"\"\"Computes BLEU score between reference and candidate text.\"\"\"\n",
    "    if pd.isna(reference) or pd.isna(candidate):  # handling missing values\n",
    "        return 0.0\n",
    "    reference_tokens = reference.split()\n",
    "    candidate_tokens = candidate.split()\n",
    "    return sentence_bleu([reference_tokens], candidate_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:11:20.736946Z",
     "iopub.status.busy": "2025-03-22T12:11:20.736727Z",
     "iopub.status.idle": "2025-03-22T12:11:20.974597Z",
     "shell.execute_reply": "2025-03-22T12:11:20.973677Z",
     "shell.execute_reply.started": "2025-03-22T12:11:20.736928Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"/kaggle/input/bart-cs/test_bart_counterspeech.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:11:20.975957Z",
     "iopub.status.busy": "2025-03-22T12:11:20.975568Z",
     "iopub.status.idle": "2025-03-22T12:11:21.946713Z",
     "shell.execute_reply": "2025-03-22T12:11:21.945893Z",
     "shell.execute_reply.started": "2025-03-22T12:11:20.975928Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 **Mean BLEU Score (BART):** 0.2862\n"
     ]
    }
   ],
   "source": [
    "# BLEU score for each row\n",
    "test_df[\"bleu_bart\"] = test_df.apply(lambda row: calculate_bleu(row[\"counterspeech\"], row[\"BART_counterspeech\"]), axis=1)\n",
    "\n",
    "# BLEU score\n",
    "mean_bleu_bart = test_df[\"bleu_bart\"].mean()\n",
    "print(f\"📌 **Mean BLEU Score (BART):** {mean_bleu_bart:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:12:24.190540Z",
     "iopub.status.busy": "2025-03-22T12:12:24.190233Z",
     "iopub.status.idle": "2025-03-22T12:13:07.102698Z",
     "shell.execute_reply": "2025-03-22T12:13:07.101792Z",
     "shell.execute_reply.started": "2025-03-22T12:12:24.190514Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423a4c25f2f1404c832109a6f512de7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d238ea1a7f764370b6e3a8e691e1ed9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533fc578aa5c4476b06b348b835f2842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6eb00d339eb4b42b93e720096225a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba4350a17d44412ad9445b11b219034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c38c0b97c346a59545d0a7d0ec33a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da27647f0ac14f6e9751680ffd15b5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439a255695c74caea5900b2597b8d5ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 32.61 seconds, 91.11 sentences/sec\n",
      "📌 **Mean BERT-F1 Score (BART):** 0.8726\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "references = test_df[\"counterspeech\"].fillna(\"\").tolist()\n",
    "bart_outputs = test_df[\"BART_counterspeech\"].fillna(\"\").tolist()\n",
    "\n",
    "# BERT Scores\n",
    "P_bart, R_bart, F1_bart = score(bart_outputs, references, lang=\"en\", verbose=True)\n",
    "\n",
    "test_df[\"bert_p_bart\"] = P_bart.tolist()\n",
    "test_df[\"bert_r_bart\"] = R_bart.tolist()\n",
    "test_df[\"bert_f1_bart\"] = F1_bart.tolist()\n",
    "\n",
    "# BERT-F1 score\n",
    "mean_bert_f1_bart = F1_bart.mean().item()\n",
    "print(f\"📌 **Mean BERT-F1 Score (BART):** {mean_bert_f1_bart:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6928939,
     "sourceId": 11113264,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6938903,
     "sourceId": 11126415,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
